{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-07QJORT.verizon.net:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1ea720e04a8>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"location_temp.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = spark.read.format(\"csv\").option(\"header\",\"true\").load(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------+------------+\n",
      "|         event_date|location_id|temp_celcius|\n",
      "+-------------------+-----------+------------+\n",
      "|03/04/2019 19:48:06|       loc0|          29|\n",
      "|03/04/2019 19:53:06|       loc0|          27|\n",
      "|03/04/2019 19:58:06|       loc0|          28|\n",
      "|03/04/2019 20:03:06|       loc0|          30|\n",
      "|03/04/2019 20:08:06|       loc0|          27|\n",
      "|03/04/2019 20:13:06|       loc0|          27|\n",
      "|03/04/2019 20:18:06|       loc0|          27|\n",
      "|03/04/2019 20:23:06|       loc0|          29|\n",
      "|03/04/2019 20:28:06|       loc0|          32|\n",
      "|03/04/2019 20:33:06|       loc0|          35|\n",
      "+-------------------+-----------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---+----+----+---+\n",
      "|                _c0|_c1| _c2| _c3|_c4|\n",
      "+-------------------+---+----+----+---+\n",
      "|03/05/2019 08:06:14|100|0.57|0.51| 47|\n",
      "|03/05/2019 08:11:14|100|0.47|0.62| 43|\n",
      "|03/05/2019 08:16:14|100|0.56|0.57| 62|\n",
      "|03/05/2019 08:21:14|100|0.57|0.56| 50|\n",
      "|03/05/2019 08:26:14|100|0.35|0.46| 43|\n",
      "|03/05/2019 08:31:14|100|0.41|0.58| 48|\n",
      "|03/05/2019 08:36:14|100|0.57|0.35| 58|\n",
      "|03/05/2019 08:41:14|100|0.41| 0.4| 58|\n",
      "|03/05/2019 08:46:14|100|0.53|0.35| 62|\n",
      "|03/05/2019 08:51:14|100|0.51| 0.6| 45|\n",
      "+-------------------+---+----+----+---+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_path_no_header = \"utilization.csv\"\n",
    "df2 = spark.read.format(\"csv\").option(\"header\",\"false\").option(\"inferSchema\",\"true\").load(file_path_no_header)\n",
    "df2.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.withColumnRenamed(\"_c0\",\"event_datetime\") \\\n",
    "         .withColumnRenamed(\"_c1\", \"server_id\") \\\n",
    "         .withColumnRenamed(\"_c2\", \"cpu_utilization\") \\\n",
    "         .withColumnRenamed(\"_c3\", \"free_memory\") \\\n",
    "         .withColumnRenamed(\"_c4\", \"session_count\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+---------------+-----------+-------------+\n",
      "|     event_datetime|server_id|cpu_utilization|free_memory|session_count|\n",
      "+-------------------+---------+---------------+-----------+-------------+\n",
      "|03/05/2019 08:06:14|      100|           0.57|       0.51|           47|\n",
      "|03/05/2019 08:11:14|      100|           0.47|       0.62|           43|\n",
      "|03/05/2019 08:16:14|      100|           0.56|       0.57|           62|\n",
      "|03/05/2019 08:21:14|      100|           0.57|       0.56|           50|\n",
      "|03/05/2019 08:26:14|      100|           0.35|       0.46|           43|\n",
      "|03/05/2019 08:31:14|      100|           0.41|       0.58|           48|\n",
      "|03/05/2019 08:36:14|      100|           0.57|       0.35|           58|\n",
      "|03/05/2019 08:41:14|      100|           0.41|        0.4|           58|\n",
      "|03/05/2019 08:46:14|      100|           0.53|       0.35|           62|\n",
      "|03/05/2019 08:51:14|      100|           0.51|        0.6|           45|\n",
      "+-------------------+---------+---------------+-----------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['event_datetime',\n",
       " 'server_id',\n",
       " 'cpu_utilization',\n",
       " 'free_memory',\n",
       " 'session_count']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+---------------+-----------+-------------+\n",
      "|     event_datetime|server_id|cpu_utilization|free_memory|session_count|\n",
      "+-------------------+---------+---------------+-----------+-------------+\n",
      "|03/05/2019 08:51:14|      100|           0.51|        0.6|           45|\n",
      "|03/05/2019 09:41:14|      100|           0.55|       0.59|           63|\n",
      "|03/05/2019 09:46:14|      100|           0.29|        0.6|           44|\n",
      "|03/05/2019 11:06:14|      100|           0.32|       0.35|           71|\n",
      "|03/05/2019 12:26:14|      100|           0.67|        0.6|           66|\n",
      "|03/05/2019 15:26:14|      100|           0.58|       0.66|           53|\n",
      "|03/05/2019 16:11:14|      100|           0.54|       0.37|           59|\n",
      "|03/05/2019 17:16:14|      100|           0.46|       0.69|           41|\n",
      "|03/05/2019 18:11:14|      100|           0.63|       0.59|           67|\n",
      "|03/05/2019 18:31:14|      100|           0.28|       0.72|           57|\n",
      "+-------------------+---------+---------------+-----------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2_sample = df2.sample(False, fraction=0.1)\n",
    "df2_sample.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49951"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_sample.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+---------------+-----------+-------------+\n",
      "|     event_datetime|server_id|cpu_utilization|free_memory|session_count|\n",
      "+-------------------+---------+---------------+-----------+-------------+\n",
      "|03/05/2019 08:06:41|      116|            0.4|       0.53|           51|\n",
      "|03/05/2019 08:06:43|      117|           0.71|       0.61|           60|\n",
      "|03/05/2019 08:07:25|      140|           0.61|       0.15|           69|\n",
      "|03/05/2019 08:11:21|      104|           0.62|       0.15|           86|\n",
      "|03/05/2019 08:11:29|      109|           0.67|       0.46|           68|\n",
      "|03/05/2019 08:11:41|      116|           0.44|       0.38|           49|\n",
      "|03/05/2019 08:11:43|      117|           0.44|       0.51|           75|\n",
      "|03/05/2019 08:12:13|      134|           0.34|       0.64|           73|\n",
      "|03/05/2019 08:12:33|      144|           0.54|       0.26|           86|\n",
      "|03/05/2019 08:12:44|      149|            0.9|       0.34|           85|\n",
      "+-------------------+---------+---------------+-----------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2_sort = df2_sample.sort('event_datetime')\n",
    "df2_sort.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------+------------+\n",
      "|         event_date|location_id|temp_celcius|\n",
      "+-------------------+-----------+------------+\n",
      "|03/04/2019 19:48:06|       loc0|          29|\n",
      "|03/04/2019 19:53:06|       loc0|          27|\n",
      "|03/04/2019 19:58:06|       loc0|          28|\n",
      "|03/04/2019 20:03:06|       loc0|          30|\n",
      "|03/04/2019 20:08:06|       loc0|          27|\n",
      "|03/04/2019 20:13:06|       loc0|          27|\n",
      "|03/04/2019 20:18:06|       loc0|          27|\n",
      "|03/04/2019 20:23:06|       loc0|          29|\n",
      "|03/04/2019 20:28:06|       loc0|          32|\n",
      "|03/04/2019 20:33:06|       loc0|          35|\n",
      "|03/04/2019 20:38:06|       loc0|          32|\n",
      "|03/04/2019 20:43:06|       loc0|          28|\n",
      "|03/04/2019 20:48:06|       loc0|          28|\n",
      "|03/04/2019 20:53:06|       loc0|          32|\n",
      "|03/04/2019 20:58:06|       loc0|          34|\n",
      "|03/04/2019 21:03:06|       loc0|          33|\n",
      "|03/04/2019 21:08:06|       loc0|          27|\n",
      "|03/04/2019 21:13:06|       loc0|          28|\n",
      "|03/04/2019 21:18:06|       loc0|          33|\n",
      "|03/04/2019 21:23:06|       loc0|          28|\n",
      "+-------------------+-----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.filter(df1['location_id'] == 'loc0').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|location_id|count|\n",
      "+-----------+-----+\n",
      "|     loc196| 1000|\n",
      "|     loc226| 1000|\n",
      "|     loc463| 1000|\n",
      "|     loc150| 1000|\n",
      "|     loc292| 1000|\n",
      "|     loc311| 1000|\n",
      "|      loc22| 1000|\n",
      "|     loc351| 1000|\n",
      "|     loc370| 1000|\n",
      "|     loc419| 1000|\n",
      "|      loc31| 1000|\n",
      "|     loc305| 1000|\n",
      "|      loc82| 1000|\n",
      "|      loc90| 1000|\n",
      "|     loc118| 1000|\n",
      "|     loc195| 1000|\n",
      "|     loc208| 1000|\n",
      "|      loc39| 1000|\n",
      "|      loc75| 1000|\n",
      "|     loc228| 1000|\n",
      "+-----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.groupBy('location_id').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+\n",
      "|location_id|avg(temp_celcius)|\n",
      "+-----------+-----------------+\n",
      "|     loc196|           29.225|\n",
      "|     loc226|           25.306|\n",
      "|     loc463|           23.317|\n",
      "|     loc150|           32.188|\n",
      "|     loc292|           29.159|\n",
      "|     loc311|           24.308|\n",
      "|      loc22|           28.251|\n",
      "|     loc351|           28.194|\n",
      "|     loc370|            29.14|\n",
      "|     loc419|           29.141|\n",
      "|      loc31|           25.196|\n",
      "|     loc305|           27.314|\n",
      "|      loc82|           27.355|\n",
      "|      loc90|           23.216|\n",
      "|     loc118|           24.219|\n",
      "|     loc195|            27.25|\n",
      "|     loc208|           26.206|\n",
      "|      loc39|           25.199|\n",
      "|      loc75|           23.209|\n",
      "|     loc228|           27.295|\n",
      "+-----------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.groupBy('location_id').agg({'temp_celcius':'mean'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+\n",
      "|location_id|max(temp_celcius)|\n",
      "+-----------+-----------------+\n",
      "|     loc196|               36|\n",
      "|     loc226|               32|\n",
      "|     loc463|               30|\n",
      "|     loc150|               39|\n",
      "|     loc292|               36|\n",
      "|     loc311|               31|\n",
      "|      loc22|               35|\n",
      "|     loc351|               35|\n",
      "|     loc370|               36|\n",
      "|     loc419|               36|\n",
      "|     loc305|               34|\n",
      "|      loc31|               32|\n",
      "|     loc118|               31|\n",
      "|     loc195|               34|\n",
      "|     loc208|               33|\n",
      "|      loc82|               34|\n",
      "|      loc90|               30|\n",
      "|     loc228|               34|\n",
      "|      loc39|               32|\n",
      "|      loc75|               30|\n",
      "+-----------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.groupBy('location_id').agg({'temp_celcius':'max'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50059"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_s1 = df1.sample(fraction=0.1, withReplacement=False)\n",
    "df_s1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.write.csv('df1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
